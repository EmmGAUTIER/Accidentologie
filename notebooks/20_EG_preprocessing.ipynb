{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "aadb9de204a24f6fab1f664170561ed7",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "db654247dd3246adadfea0c6a26e1e20",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 944,
    "execution_start": 1725370954239,
    "source_hash": "bfbcf83a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import json\n",
    "\n",
    "rep_src   = \"../data/raw/\"       # Fichiers téléchargés avant traitements\n",
    "rep_inter = \"../data/inter/\"     # Des fichiers intermédiaires sont utilisés\n",
    "rep_dst   = \"../data/processed/\" # Fichiers utilisés par la modélisation\n",
    "\n",
    "# La liste actions sert à stocker la liste des actions réalisées.\n",
    "# Elle est affichée en fin de notebook et sert à la rédaction du rapport\n",
    "# La fonction log_action affiche et stocke dans actions[].\n",
    "actions  = []\n",
    "def log_action(str):\n",
    "    print (f\" - {str}\")\n",
    "    actions.append(str)\n",
    "\n",
    "# Il y a des variables à écarter, nous enregistrons la liste dans var_ecartees\n",
    "# Nous enregistrons pour chaque var. écartée son nom et la raison.\n",
    "var_ecartees = []\n",
    "    \n",
    "# Lecture de la liste des fichiers, cette liste comprend : les noms\n",
    "# des fichiers, les séparateurs, la période (\"phase\"), les conversions\n",
    "# de type à réaliser et quelques autre infos.\n",
    "with open(\"./desc_fic_raw.json\", 'r', encoding='utf-8') as fichier:\n",
    "    des_fic_raw = json.load(fichier)\n",
    "\n",
    "# Lecture de la description des variables avec leurs libellés\n",
    "# et les correspondances des modalités pour des affichages explicites\n",
    "with open(\"./desc_vars_model.json\", 'r', encoding='utf-8') as fichier:\n",
    "    desc_vars = json.load(fichier)\n",
    "\n",
    "dfrub = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7f63113bf2b94775ae57b75a7bd8193e",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Lecture des données\n",
    "\n",
    "Les données sont réparties dans 4 rubriques et dans 4 années de 2019 à 2022\n",
    "\n",
    "Les informations sur les fichiers contenues dans le fichier desc_fic_raw.json\n",
    "contiennent :\n",
    "  - Le nom du fichier ;\n",
    "  - Le séparateur ;\n",
    "  - La phase : jusqu'à 2018 ou à partir de 2019 ;\n",
    "  - les conversions de types dans dtypes à réaliser lors du chargement ;\n",
    " Le code de la cellule suivante réalise :\n",
    "  - la lecture des fichiers ;\n",
    "  - des conversions de type et le remplacement des \" -1\" par \"-1\"\n",
    "  - le renommage d'une colonne d'un fichier ;\n",
    "  - la concaténation des fichiers de chaque rubrique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "c72789f2254848bbba6210339f676c9c",
    "deepnote_cell_type": "code",
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 13664,
    "execution_start": 1725370955234,
    "source_hash": "9e33ca72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rubrique :  caracteristiques\n",
      "caracteristiques-2019.csv (58840, 15)\n",
      "caracteristiques-2020.csv (47744, 15)\n",
      "carcteristiques-2021.csv (56518, 15)\n",
      "  - rename  {'Accident_Id': 'Num_Acc'}\n",
      "carcteristiques-2022.csv (55302, 15)\n",
      "Nombre de DataFrames  :  4\n",
      "Nombre d'observations :  218404 218404\n",
      "Colonnes du DataFrame :  15\n",
      "\n",
      "Rubrique :  usagers\n",
      "usagers-2019.csv (132977, 15)\n",
      "usagers-2020.csv (105295, 15)\n",
      "usagers-2021.csv (129248, 16)\n",
      "usagers-2022.csv (126662, 16)\n",
      "Nombre de DataFrames  :  4\n",
      "Nombre d'observations :  494182 494182\n",
      "Colonnes du DataFrame :  16\n",
      "\n",
      "Rubrique :  vehicules\n",
      "vehicules-2019.csv (100710, 11)\n",
      "vehicules-2020.csv (81066, 11)\n",
      "vehicules-2021.csv (97315, 11)\n",
      "vehicules-2022.csv (94493, 11)\n",
      "Nombre de DataFrames  :  4\n",
      "Nombre d'observations :  373584 373584\n",
      "Colonnes du DataFrame :  11\n",
      "\n",
      "Rubrique :  lieux\n",
      "lieux-2019.csv (58840, 18)\n",
      "lieux-2020.csv (47744, 18)\n",
      "lieux-2021.csv (56518, 18)\n",
      "lieux-2022.csv (55302, 18)\n",
      "Nombre de DataFrames  :  4\n",
      "Nombre d'observations :  218404 218404\n",
      "Colonnes du DataFrame :  18\n"
     ]
    }
   ],
   "source": [
    "#!pwd\n",
    "#!ls -l data/raw\n",
    "\n",
    "# Traitement  : remplacement de \" -1\" par \"-1\"\n",
    "for rubrique, description_rub in des_fic_raw.items():  # Pour chaque rubrique\n",
    "    nb_obs = 0  # nombre total d'observation (lignes, hors entêtes)\n",
    "\n",
    "    print ()\n",
    "    print(\"Rubrique : \", rubrique)\n",
    "    \n",
    "    dfl = []\n",
    "    dtype = description_rub.get(\"dtypes\")\n",
    "    \n",
    "\n",
    "    for fichier_origine in description_rub[\"fichiers\"]:  # Pour chaque fichier annuel\n",
    "        if fichier_origine.get(\"phase\") == \"2\":\n",
    "            nom_fichier = fichier_origine[\"nom\"]\n",
    "            # lecture du fichier\n",
    "            df = pd.read_csv(rep_src + nom_fichier,\n",
    "                             sep=fichier_origine[\"sep\"],\n",
    "                             dtype=dtype,\n",
    "                             encoding=\"latin_1\",\n",
    "                             index_col=False,\n",
    "                             quotechar=\"\\\"\",\n",
    "                             low_memory=False)\n",
    "            nb_obs += df.shape[0]\n",
    "            if fichier_origine.get(\"rename_cols\") is not None:\n",
    "                df = df.rename(columns=fichier_origine.get(\"rename_cols\"))\n",
    "                print(\"  - rename \", fichier_origine.get(\"rename_cols\"))\n",
    "            print(nom_fichier, df.shape)  # Pour info et mise au point\n",
    "            dfl.append(df)\n",
    "\n",
    "    #df_rub = pd.concat(dfl)    # Concaténation de tous les DataFrames annuels\n",
    "    dfrub[rubrique] = pd.concat(dfl) # Concaténation de tous les DataFrames annuels (2019->2022)\n",
    "    \n",
    "    # Remplacement des \" -1\" par \"-1\"\n",
    "    # Les valeurs manquantes sont codées \"-1\" et parfois \" -1\", avec une espace en plus\n",
    "    # Il faut alors supprimer cette espace qui n'a pas de sens.\n",
    "    dfrub[rubrique] = dfrub[rubrique].replace(\" -1\", \"-1\")\n",
    "\n",
    "    print(\"Nombre de DataFrames  : \", len(dfl))\n",
    "    print(\"Nombre d'observations : \", nb_obs, dfrub[rubrique].shape[0])\n",
    "    print(\"Colonnes du DataFrame : \", dfrub[rubrique].shape[1])\n",
    "\n",
    "    dfrub[rubrique].to_csv(rep_dst + rubrique + \".csv\", sep='\\t', index=False)\n",
    "\n",
    "dfu = dfrub[\"usagers\"]\n",
    "dfv = dfrub[\"vehicules\"]\n",
    "dfl = dfrub[\"lieux\"]\n",
    "dfc = dfrub[\"caracteristiques\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "85aa888db8dc4b8390f2559c9315facf",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Enregistrement des 4 rubriques de 2019 à 2022\n",
    "Ces enregistrements servent à l'exploration et à la mise au point. Il sont provisoires. Ce code est commenté en temps normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "0609e71248c94dd1956438a22f29758b",
    "deepnote_cell_type": "code",
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 8161,
    "execution_start": 1725370968954,
    "source_hash": "563a732d"
   },
   "outputs": [],
   "source": [
    "dfc.to_csv (rep_inter+'caracteristiques_raw_4.csv',   sep = '\\t')\n",
    "dfl.to_csv (rep_inter+'lieux_raw_4.csv',              sep = '\\t')\n",
    "dfu.to_csv (rep_inter+'usagers_raw_4.csv',            sep = '\\t')\n",
    "dfv.to_csv (rep_inter+'vehicules_raw_4.csv',          sep = '\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c60e3baf6c084ba6861958137a6cdec6",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Jointure des 4 rubriques\n",
    "\n",
    "Les jointures sont toutes faites avec le champ Num_Acc\n",
    "Le type de Num_Acc est forcé à int lors de la lecture par read_csv()\n",
    "La dernière jointure avec les véhicules est faite avec, en plus,\n",
    "les champs num_veh et id_vehicule.\n",
    "Les jointures sont \"à gauche\" (\"left\")\n",
    "pour conserver le nombre d'usagers.\n",
    "Les nombres d'observations et de variables affichés avant et après\n",
    "chaque jointure permettent de vérifier les jointures.\n",
    "Il y a 494 182 usagers avant les jointures et le DataFrame résultant\n",
    "a ce même nombre d'observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "51df6f77d16c4e6db86dd97956bd2561",
    "deepnote_cell_type": "code",
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 2303,
    "execution_start": 1725370977170,
    "source_hash": "bec57eb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - Jointure usagers  <---  caracteristiques\n",
      "\n",
      "Taille usagers          :  (494182, 16)\n",
      "Taille caractéristiques :  (218404, 15)\n",
      "Tailles df résultant    :  (494182, 30)\n",
      "\n",
      " - Jointure (usagers et caracteristiques)  <---  lieux\n",
      "\n",
      "Taille DataFrame        :  (494182, 30)\n",
      "Taille lieux            :  (218404, 18)\n",
      "Tailles df résultant    :  (494182, 47)\n",
      "\n",
      " - Jointure (usagers, caracteristiques et lieux)  <---  vehicules\n",
      "\n",
      "Taille DataFrame        :  (494182, 47)\n",
      "Taille vehicules        :  (373584, 11)\n",
      "Tailles df résultant    :  (494182, 55)\n",
      "\n",
      "Colonnes résultantes :  Index(['Num_Acc', 'id_vehicule', 'num_veh', 'place', 'catu', 'grav', 'sexe',\n",
      "       'an_nais', 'trajet', 'secu1', 'secu2', 'secu3', 'locp', 'actp', 'etatp',\n",
      "       'id_usager', 'jour', 'mois', 'an', 'hrmn', 'lum', 'dep', 'com', 'agg',\n",
      "       'int', 'atm', 'col', 'adr', 'lat', 'long', 'catr', 'voie', 'v1', 'v2',\n",
      "       'circ', 'nbv', 'vosp', 'prof', 'pr', 'pr1', 'plan', 'lartpc', 'larrout',\n",
      "       'surf', 'infra', 'situ', 'vma', 'senc', 'catv', 'obs', 'obsm', 'choc',\n",
      "       'manv', 'motor', 'occutc'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 494182 entries, 0 to 494181\n",
      "Data columns (total 55 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   Num_Acc      494182 non-null  int64  \n",
      " 1   id_vehicule  494182 non-null  object \n",
      " 2   num_veh      494182 non-null  object \n",
      " 3   place        494182 non-null  object \n",
      " 4   catu         494182 non-null  object \n",
      " 5   grav         494182 non-null  object \n",
      " 6   sexe         494182 non-null  object \n",
      " 7   an_nais      488241 non-null  object \n",
      " 8   trajet       494182 non-null  object \n",
      " 9   secu1        494182 non-null  object \n",
      " 10  secu2        494182 non-null  object \n",
      " 11  secu3        494182 non-null  object \n",
      " 12  locp         494182 non-null  object \n",
      " 13  actp         494182 non-null  object \n",
      " 14  etatp        494182 non-null  object \n",
      " 15  id_usager    255910 non-null  object \n",
      " 16  jour         494182 non-null  int64  \n",
      " 17  mois         494182 non-null  int64  \n",
      " 18  an           494182 non-null  int64  \n",
      " 19  hrmn         494182 non-null  object \n",
      " 20  lum          494182 non-null  object \n",
      " 21  dep          494182 non-null  object \n",
      " 22  com          494182 non-null  object \n",
      " 23  agg          494182 non-null  int64  \n",
      " 24  int          494182 non-null  object \n",
      " 25  atm          494182 non-null  object \n",
      " 26  col          494182 non-null  object \n",
      " 27  adr          488131 non-null  object \n",
      " 28  lat          494182 non-null  object \n",
      " 29  long         494182 non-null  object \n",
      " 30  catr         494182 non-null  object \n",
      " 31  voie         446618 non-null  object \n",
      " 32  v1           469586 non-null  object \n",
      " 33  v2           39542 non-null   object \n",
      " 34  circ         494182 non-null  object \n",
      " 35  nbv          494182 non-null  object \n",
      " 36  vosp         494182 non-null  object \n",
      " 37  prof         494182 non-null  object \n",
      " 38  pr           494182 non-null  object \n",
      " 39  pr1          494182 non-null  object \n",
      " 40  plan         494182 non-null  object \n",
      " 41  lartpc       1082 non-null    object \n",
      " 42  larrout      362036 non-null  object \n",
      " 43  surf         494182 non-null  object \n",
      " 44  infra        494182 non-null  object \n",
      " 45  situ         494182 non-null  object \n",
      " 46  vma          494182 non-null  float64\n",
      " 47  senc         494182 non-null  object \n",
      " 48  catv         494182 non-null  int64  \n",
      " 49  obs          494182 non-null  object \n",
      " 50  obsm         494182 non-null  object \n",
      " 51  choc         494182 non-null  object \n",
      " 52  manv         494182 non-null  object \n",
      " 53  motor        494182 non-null  object \n",
      " 54  occutc       6212 non-null    object \n",
      "dtypes: float64(1), int64(6), object(48)\n",
      "memory usage: 207.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Jointures des 4 rubriques \n",
    "########################################################################\n",
    "\n",
    "print(\"\")\n",
    "log_action(\"Jointure usagers  <---  caracteristiques\")\n",
    "#print(\"Un pour un\")\n",
    "print ()\n",
    "print(\"Taille usagers          : \", dfu.shape)\n",
    "print(\"Taille caractéristiques : \", dfc.shape)\n",
    "df = pd.merge(dfu, dfc, on=\"Num_Acc\", how = \"left\")\n",
    "print(\"Tailles df résultant    : \", df.shape)\n",
    "\n",
    "print(\"\")\n",
    "log_action(\"Jointure (usagers et caracteristiques)  <---  lieux\")\n",
    "print()\n",
    "print(\"Taille DataFrame        : \", df.shape)\n",
    "print(\"Taille lieux            : \", dfl.shape)\n",
    "df = pd.merge(df, dfl, on=\"Num_Acc\", how = \"left\")\n",
    "print(\"Tailles df résultant    : \", df.shape)\n",
    "\n",
    "print(\"\")\n",
    "log_action(\"Jointure (usagers, caracteristiques et lieux)  <---  vehicules\")\n",
    "print()\n",
    "print(\"Taille DataFrame        : \", df.shape)\n",
    "print(\"Taille vehicules        : \", dfv.shape)\n",
    "df = pd.merge(df, dfv, on=[\"Num_Acc\", \"id_vehicule\", \"num_veh\"], how = \"left\")\n",
    "\n",
    "print(\"Tailles df résultant    : \", df.shape)\n",
    "print ()\n",
    "print (\"Colonnes résultantes : \", df.columns)\n",
    "\n",
    "print (df.info(max_cols=1000, show_counts=True))\n",
    "# Libérons de la mémoire.\n",
    "# Les DataFrames des 4 rubriques ne seront plus utilisés\n",
    "dfc = None\n",
    "dfl = None\n",
    "dfu = None\n",
    "dfv = None\n",
    "dfrub = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "15779e061de44457a7a6e1d7ec1609b4",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Enregistrement du jeu de données avant pré-traitement\n",
    "\n",
    "Cet enregistrement intermédiaire sert à la mise au point.\n",
    "La ligne de code est commentée en temps normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "795ebee5a4aa472b9d6955c4e5ca5e09",
    "deepnote_cell_type": "code",
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 0,
    "execution_start": 1725370979514,
    "source_hash": "b500f1bc"
   },
   "outputs": [],
   "source": [
    "# df.to_csv(rep_inter+'data_raw_4.csv', sep = '\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ee85a6fd76e240ea86eaa1bf81fa1a8f",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Suppression d'observations\n",
    "Nous supprimons les observations dont la gravité est inconnue,\n",
    "la gravité inconnue est codée -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "da66374e32714b3b9dfab763b429b89e",
    "deepnote_cell_type": "code",
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 156,
    "execution_start": 1725370979590,
    "source_hash": "9f7ae458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'observations avant suppression 494182\n",
      "Nombre d'observations supprimées        0\n",
      "Nombre d'observations après suppression 494182\n",
      " - Suppression de 0 observations dont la gravité est inconnue (codée -1)\n"
     ]
    }
   ],
   "source": [
    "nb_avant = df.shape[0]\n",
    "print (f\"Nombre d'observations avant suppression {nb_avant}\")\n",
    "df1 = df.loc[df.grav!='-1',:]\n",
    "print (f\"Nombre d'observations supprimées        {nb_avant- df.shape[0]}\")\n",
    "print (f\"Nombre d'observations après suppression {df.shape[0]}\")\n",
    "log_action(f\"Suppression de {nb_avant- df.shape[0]} observations dont la gravité est inconnue (codée -1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5789f69b8324407dbe5246fcbc52e6b2",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Création de variables\n",
    "\n",
    "## Création de la variable indiquant un jour ferié\n",
    "\n",
    "Cette variable nous permettra de déterminer si les jours feriés\n",
    "expliquent la gravité des accidents. Les jours fériés sont les dimanches\n",
    "et les jours de fête.\n",
    "\n",
    "## Création de la variable du jour de la semaine\n",
    "\n",
    "Cette variable nous permettra de déterminer si le jour de la\n",
    "semaine explique la gravité des accidents.\n",
    "\n",
    "## Création de la variable indiquant l'âge\n",
    "\n",
    "Le jeu de données contient l'année de naissance des usagers et l'année\n",
    "de l'accident. Nous créons la variable age égal à la différence\n",
    "entre l'année de l'accident et l'année de naissance.\n",
    "Lorsque l'année de naissance est inconnue l'âge est codé -1\n",
    "TODO : Que faire des années de naissance inconnue ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "7cfad10f6f8744378a2230d081eee288",
    "deepnote_cell_type": "code",
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 0,
    "execution_start": 1725370979798,
    "source_hash": "b623e53d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "25f0a5b4185a4f0d8bfffe7850397446",
    "deepnote_cell_type": "code",
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 1332,
    "execution_start": 1725370979850,
    "source_hash": "cc2b582f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Inclusion du jour de la semaine dans le fichier\n",
      "Jours de la semaine : \n",
      "jsem\n",
      "1    66099\n",
      "2    70041\n",
      "3    70392\n",
      "4    71101\n",
      "5    81515\n",
      "6    72974\n",
      "7    62060\n",
      "Name: count, dtype: int64\n",
      " - Création de la variable jsem : jour de la semaine\n",
      "Jours ouvrés et fériés\n",
      "ferie\n",
      "False    425236\n",
      "True      68946\n",
      "Name: count, dtype: int64\n",
      " - Création de la variable ferie : jour férié, dimanches et autres fêtes\n",
      "5941\n",
      "5941\n",
      " - Création de la variable age : différence entre l'année de l'accident et l'année de naissance\n"
     ]
    }
   ],
   "source": [
    "# Creation de colonnes :\n",
    "#   - ferie : 0 jour ouvré, 1 : jour ferié\n",
    "#   - jsem : jour de la semaine : lundi : 1 , ... , 7 : dimanche\n",
    "\n",
    "##############################################################################\n",
    "# Inclusion du jour de la semaine\n",
    "##############################################################################\n",
    "\n",
    "print(\"  - Inclusion du jour de la semaine dans le fichier\")\n",
    "df_date = df[[\"an\", \"mois\", \"jour\"]]\n",
    "df_date = df_date.rename({\"an\": \"year\", \"mois\": \"month\", \"jour\": \"day\"}, axis=1)\n",
    "df_date[\"ts\"] = pd.to_datetime(df_date)\n",
    "#  weekday() return :  Monday is 0 and Sunday is 6.\n",
    "# La modalité zéro signifiant parfois non renseigné ou non applicable\n",
    "# nous préférons ajouter 1 à la valeur retournée par weekday()\n",
    "df_date[\"jsem\"] = df_date.ts.apply(lambda x: x.weekday()+1)\n",
    "\n",
    "df[\"jsem\"] = df_date.jsem\n",
    "df_date = None  # Libérons un peu de mémoire\n",
    "\n",
    "print (\"Jours de la semaine : \")\n",
    "print (df.jsem.value_counts().sort_index())\n",
    "log_action (f\"Création de la variable jsem : jour de la semaine\")\n",
    "\n",
    "##############################################################################\n",
    "# Création de la variable ferie\n",
    "# elle vaut 1 si le jour est ferie, 0 sinon\n",
    "# Les jours fériés sont les dimanches et les jours de fête.\n",
    "##############################################################################\n",
    "\n",
    "df[\"ferie\"] = False\n",
    "\n",
    "# Les dimanches\n",
    "df.loc[df.jsem==7,\"ferie\"] = True\n",
    "\n",
    "# Les 1er janvier\n",
    "df.loc[(df.mois == '1') & (df.jour == '1'), 'ferie'] = True\n",
    "\n",
    "# Les 1er mai\n",
    "df.loc[(df[\"mois\"]==5) & (df[\"jour\"]==1), \"ferie\"] = True\n",
    "\n",
    "# Les 8 mai\n",
    "df.loc[(df.mois==5) & (df.jour==8), \"ferie\"] = True\n",
    "\n",
    "# Les 14 juillet\n",
    "df.loc[(df.mois==7) & (df.jour==14), \"ferie\"] = True\n",
    "\n",
    "# Les 15 août\n",
    "df.loc[(df.mois==7) & (df.jour==14), \"ferie\"] = True\n",
    "\n",
    "# Les 1er novembre\n",
    "df.loc[(df.mois==11) & (df.jour==1), \"ferie\"] = True\n",
    "\n",
    "# Les 11 novembre\n",
    "df.loc[(df.mois==11) & (df.jour==11), \"ferie\"] = True\n",
    "\n",
    "# Les 25 décembre\n",
    "df.loc[(df.mois==12) & (df.jour==25), \"ferie\"] = True\n",
    "\n",
    "# Dimanche de pâques, date variant chaque année\n",
    "df.loc[(df.an == 2019) & (df.mois==4) & (df.jour==21), \"ferie\"] = True\n",
    "df.loc[(df.an == 2020) & (df.mois==4) & (df.jour==12), \"ferie\"] = True\n",
    "df.loc[(df.an == 2021) & (df.mois==4) & (df.jour==4),  \"ferie\"] = True\n",
    "df.loc[(df.an == 2022) & (df.mois==4) & (df.jour==17), \"ferie\"] = True\n",
    "\n",
    "# Lundi de pentecôte, date variant chaque année\n",
    "df.loc[(df.an == 2019) & (df.mois==6) & (df.jour==10), \"ferie\"] = True\n",
    "df.loc[(df.an == 2020) & (df.mois==6) & (df.jour==1), \"ferie\"] = True\n",
    "df.loc[(df.an == 2021) & (df.mois==5) & (df.jour==24),  \"ferie\"] = True\n",
    "df.loc[(df.an == 2022) & (df.mois==6) & (df.jour==6), \"ferie\"] = True\n",
    "\n",
    "# Jeudi de l'ascension, date variant chaque année\n",
    "df.loc[(df.an == 2019) & (df.mois==5) & (df.jour==30), \"ferie\"] = True\n",
    "df.loc[(df.an == 2020) & (df.mois==5) & (df.jour==21), \"ferie\"] = True\n",
    "df.loc[(df.an == 2021) & (df.mois==5) & (df.jour==13),  \"ferie\"] = True\n",
    "df.loc[(df.an == 2022) & (df.mois==5) & (df.jour==26), \"ferie\"] = True\n",
    "\n",
    "# Saint Étienne en alsace Moselle, le 26 décembre\n",
    "df.loc[ df.dep.isin([57, 67, 68]) & (df.mois==12) & (df.jour==26), \"ferie\"] = True\n",
    "\n",
    "# Abolition de l'esclavage en Guadeloupe\n",
    "df.loc[(df.dep == 971) & (df.mois==5) & (df.jour==27), \"ferie\"] = True\n",
    "\n",
    "# Abolition de l'esclavage en Martinique\n",
    "df.loc[(df.dep == 972) & (df.mois==5) & (df.jour==22), \"ferie\"] = True\n",
    "\n",
    "# Abolition de l'esclavage en Guyane\n",
    "df.loc[(df.dep == 973) & (df.mois==6) & (df.jour==10), \"ferie\"] = True\n",
    "\n",
    "# Abolition de l'esclavage à la Réunion\n",
    "df.loc[(df.dep == 974) & (df.mois==12) & (df.jour==20), \"ferie\"] = True\n",
    "\n",
    "# Abolition de l'esclavage à Mayotte\n",
    "df.loc[(df.dep == 976) & (df.mois==4) & (df.jour==27), \"ferie\"] = True\n",
    "\n",
    "# Abolition de l'esclavage à Saint-Barthélémy\n",
    "df.loc[(df.dep == 977) & (df.mois==10) & (df.jour==9), \"ferie\"] = True\n",
    "\n",
    "# Abolition de l'esclavage à Saint-Martin\n",
    "df.loc[(df.dep == 978) & (df.mois==5) & (df.jour==28), \"ferie\"] = True\n",
    "\n",
    "print (\"Jours ouvrés et fériés\")\n",
    "print (df.ferie.value_counts())\n",
    "# TOTO : Ajouter les jours fériés autres que les dimanches\n",
    "log_action (f\"Création de la variable ferie : jour férié, dimanches et autres fêtes\")\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Création de la variable age\n",
    "# Elle est égale à l'année de l'accident moins l'année de naissance à un an près.\n",
    "# L'année de naissance n'est pas toujours connue, elle est alors codée -1\n",
    "# TODO : gérer l'arrondi\n",
    "##############################################################################\n",
    "\n",
    "print (df.an_nais.isna().sum())\n",
    "#df.an_nais = df.an_nais.fillna(2024)\n",
    "print (df.an_nais.isna().sum())\n",
    "\n",
    "# Lorsque la date de naissance est inconnue,\n",
    "# l'âge est codé avec une valeur négative.\n",
    "ag = df.an.astype(\"int\") - df.an_nais.fillna(2030).astype (\"int\")\n",
    "ag.loc[ag<0] = -1\n",
    "df[\"age\"] = ag\n",
    "ag = None\n",
    "# df.age.value_counts().head(60)\n",
    "\n",
    "log_action (f\"Création de la variable age : différence entre l'année de l'accident et l'année de naissance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "706eb4d27ff14a319c00301016c71beb",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Dichotomisations  / catégorisations\n",
    "La plupart des variables du jeu de données sont qualitatives et\n",
    "le modèle entraîné doit faire de la catégorisation.\n",
    "Nous procédons alors à la dichotomisation des variables catégorielles.\n",
    "Nous avons constaté la présence de valeurs non renseignées dans le jeu de données,\n",
    "elles sont parfois absentes et le plus souvent codées \"-1\" ou \" -1\".\n",
    "Nous avons aussi constaté dans certaines variables la modalité \"non applicable\",\n",
    "c'est par exemple le cas de la place de l'usager dans le véhicule lorsqu'il est piéton.\n",
    "Nous utilisons une fonction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "9d4d7f7754054a6cb078ba47867dbcfb",
    "deepnote_cell_type": "code",
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 1,
    "execution_start": 1725370981230,
    "source_hash": "bd3aabd"
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Fonction de dichotomisation adaptée\n",
    "##############################################################################\n",
    "\n",
    "def dichotomisation (df, column, var_ecartees, desc_vars=None, dummies=None, mod_ecartees = None):\n",
    "    \"\"\"\n",
    "    Cette fonction fait la dichotomisation des seules modalités de la\n",
    "    liste fournie par dummies. Elle permet de ne pas dichotomiser les\n",
    "    modalités : \"non renseigné\", \"Autre\", \"Non applicable\", ...\n",
    "    Elle utilise si possible les infos de desc_vars pour nommer les colonnes.\n",
    "    et elle complète desc_vars.\n",
    "    \"\"\"\n",
    "    try :\n",
    "        desc_vars = desc_vars.get(\"columns\")\n",
    "        col_desc = {}\n",
    "        for c in desc_vars :\n",
    "            if c.get(\"name\") == column:\n",
    "                col_desc = c\n",
    "                break\n",
    "    except :\n",
    "        col_desc = {}\n",
    "\n",
    "    #print (\"---->\", col_desc)\n",
    "    \n",
    "    if dummies is None:\n",
    "        dum = list(df[column].unique())\n",
    "    else:\n",
    "        dum = dummies\n",
    "    # print (\"---> dum : \", dum) # Uniquement pour mise au point\n",
    "    if mod_ecartees is not None:\n",
    "        dum = [x for x in dum if x not in mod_ecartees]\n",
    "    # print (\"---> dum : \", dum) # Uniquement pour mise au point\n",
    "    print()\n",
    "    # print (\"ooooo :\", len(desc_vars)) # Uniquement pour mise au point\n",
    "    \n",
    "    # Pour chaque variable correspondant à une modalité\n",
    "    for c in dum: # c : modalité\n",
    "        \n",
    "        # Le nom de la nvle variable est le nom de la var. et la modalité\n",
    "        new_col_name = column + \"_\" + str(c)\n",
    "        \n",
    "        # Création de la nouvelle variable (colonne)\n",
    "        df[new_col_name] = df[column] == c\n",
    "        \n",
    "        # Recherche d'une description existante dans la liste des descriptions\n",
    "        #desc_new_col = desc_vars.get(new_col_name)\n",
    "            \n",
    "        #if desc_new_col is None:\n",
    "        #    desc_new_col = {}\n",
    "        #    desc_new_col[\"name\"] = new_col_name\n",
    "        #    desc_new_col[\"dtype\"] = \"bool\"\n",
    "        #    values = col_desc.get(\"values\")\n",
    "        #    if values is not None and values.get(c) is not None:\n",
    "        #        desc_new_col[\"label\"] = col_desc.get(\"label\") + \" : \" + values.get(c)\n",
    "        #    else :\n",
    "        #        desc_new_col[\"label\"] = col_desc.get(\"label\")\n",
    "        #    desc_vars.append(desc_new_col)\n",
    "\n",
    "        #print (\"-->\", desc_new_col)\n",
    "    #df = df.drop(column, axis = 1)\n",
    "    var_ecartees.append ((column, \"Dichotomisation\"))\n",
    "    # df = df.copy()\n",
    "    return\n",
    "\n",
    "#dichotomisation(df, \"lum\", desc_vars, dummies = ['1', '2', '3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "9e27fa45c7ab49579ac4b8b3fe61e290",
    "deepnote_cell_type": "code",
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 1,
    "execution_start": 1725370981282,
    "source_hash": "1481c2a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'actp', 'dtype': 'object', 'label': 'Action du piéton', 'graphe': {'type': 'bar', 'order': 'value', 'orient': 'horizontal'}, 'values': {'0': 'non renseigné ou sans objet', '1': 'Se déplaçant, sens véhicule heurtant', '2': 'Se déplaçant, sens inverse du véhicule', '3': 'Traversant', '4': 'Masqué', '5': 'Jouant – courant', '6': 'Avec animal', '9': 'Autre'}, 'index': 10}\n"
     ]
    }
   ],
   "source": [
    "print(desc_vars.get (\"actp\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "bc5e4e39c87742258ad59021870bc312",
    "deepnote_cell_type": "code",
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 5941,
    "execution_start": 1725370981346,
    "source_hash": "b5a72086"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Dichotomisation des champs secu1, secu2 et secu3\n",
      " - Dichotomisation de l'âge\n",
      " - Dichotomisation de l'heure\n",
      " - Dichotomisation du sexe\n",
      " - Dichotomisation de la gravité\n",
      " - Dichotomisation du nombre de voies avec regroupement 1 à 4 puis 5 et plus\n",
      " - Dichotomisation du l'état de la surface : sèche, mouillée, glissante (3 à 9)\n",
      " - Dichotomisation de la vitesse maximale autorisée avec regroupement\n",
      " - Dichotomisation en ou hors agglomération (agg), 1 agglomération, 0 hors agglomoration\n",
      "\n",
      " - Dichotomisation de l'action du piéton (actp), modalité -1 0 et B exclues\n",
      "\n",
      " - Dichotomisation des cond. atmosphériques (atm), modalité -1 et 9 exclues\n",
      "\n",
      " - Dichotomisation de la catégorie de route (catr)), modalité -1 et 9 exclues\n",
      "\n",
      " - Dichotomisation de la catégorie d'usager (catu), modalité -1 exclue\n",
      "\n",
      " - Dichotomisation de la catégorie de véhicule (catv), modalité -1 et 0 exclues\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Dichotomisation du point de choc initial (choc), modalité -1 et 0 exclues\n",
      "\n",
      " - Dichotomisation du régime de circulation (circ), modalité -1 exclue\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Dichotomisation du type de collision (col), modalité -1 exclue\n",
      "\n",
      " - Dichotomisation de (etatp), modalité -1 exclue\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Dichotomisation de Aménagement - infrastructure (infra), modalités -1 et 0 exclues\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Dichotomisation du type d'intersection (int), modalité -1  exclues\n",
      "\n",
      " - Dichotomisation du jour de la semaine (jsem), toutes modalité \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Dichotomisation de la localisation du piéton (locp), modalités -1, 0(non renseigné) exclues\n",
      "\n",
      " - Dichotomisation des conditions lumineuses (lum), modalité -1 exclue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Dichotomisation de la manœuvre (manv), modalité -1 et 0 exclues\n",
      "\n",
      " - Dichotomisation du mois (mois), toutes modalités\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Dichotomisation de la motorisation (motor), modalité -1 et 0 exclues\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Dichotomisation de l'obstacle fixe heurté (obs), modalité -1 et 0 exclues\n",
      "\n",
      " - Dichotomisation de l'obstacle mobile heurté (obsm), modalité -1 et 0 exclues\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Dichotomisation de la place dans le véhicule (place), modalité -1 exclue\n",
      "\n",
      " - Dichotomisation du tracé en plan (plan), modalité -1 exclue\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Dichotomisation de la déclivité (prof), modalité -1 exclue\n",
      "\n",
      " - Dichotomisation du sens de circulation (senc), modalité -1, 0 et 3 exclues\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Dichotomisation de la situation de l'accident (situ), modalité -1 exclue\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n",
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Dichotomisation du motif du trajet (trajet), modalité -1 exclue\n",
      "\n",
      " - Dichotomisation de la présence d'une voie réservée (vosp), modalités -1 exclue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2107931/3161691672.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[column] == c\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Dichotomisation des champs secu 1 à 3\n",
    "##############################################################################\n",
    "# L'usager peut être protégé par plusieurs équipements, il y a trois variables\n",
    "# pour décrire ces équipements, il y a 6 types d'équipement, il faut alors\n",
    "# créer six modalités. \n",
    "\n",
    "df[\"secu_ceinture\"]   = False\n",
    "df[\"secu_casque\"]     = False\n",
    "df[\"secu_dispenfant\"] = False\n",
    "df[\"secu_gilet\"]      = False\n",
    "df[\"secu_airbag23RM\"] = False\n",
    "df[\"secu_gants\"]      = False\n",
    "\n",
    "df.loc[df.secu1 == '1', \"secu_ceinture\"] = True\n",
    "df.loc[df.secu2 == '1', \"secu_ceinture\"] = True\n",
    "df.loc[df.secu3 == '1', \"secu_ceinture\"] = True\n",
    "\n",
    "df.loc[df.secu1 == '2', \"secu_casque\"] = True\n",
    "df.loc[df.secu2 == '2', \"secu_casque\"] = True\n",
    "df.loc[df.secu3 == '2', \"secu_casque\"] = True\n",
    "\n",
    "df.loc[df.secu1 == '3', \"secu_dispenfant\"] = True\n",
    "df.loc[df.secu2 == '3', \"secu_dispenfant\"] = True\n",
    "df.loc[df.secu3 == '3', \"secu_dispenfant\"] = True\n",
    "\n",
    "df.loc[df.secu1 == '4', \"secu_gilet\"] = True\n",
    "df.loc[df.secu2 == '4', \"secu_gilet\"] = True\n",
    "df.loc[df.secu3 == '4', \"secu_gilet\"] = True\n",
    "\n",
    "df.loc[df.secu1 == '5', \"secu_airbag23RM\"] = True\n",
    "df.loc[df.secu2 == '5', \"secu_airbag23RM\"] = True\n",
    "df.loc[df.secu3 == '5', \"secu_airbag23RM\"] = True\n",
    "df.loc[df.secu1 == '7', \"secu_airbag23RM\"] = True\n",
    "df.loc[df.secu2 == '7', \"secu_airbag23RM\"] = True\n",
    "df.loc[df.secu3 == '7', \"secu_airbag23RM\"] = True\n",
    "\n",
    "df.loc[df.secu1 == '6', \"secu_gants\"] = True\n",
    "df.loc[df.secu2 == '6', \"secu_gants\"] = True\n",
    "df.loc[df.secu3 == '6', \"secu_gants\"] = True\n",
    "df.loc[df.secu1 == '7', \"secu_gants\"] = True\n",
    "df.loc[df.secu2 == '7', \"secu_gants\"] = True\n",
    "df.loc[df.secu3 == '7', \"secu_gants\"] = True\n",
    "\n",
    "var_ecartees.append((\"secu1\", \"Dichotomisation\"))\n",
    "var_ecartees.append((\"secu2\", \"Dichotomisation\"))\n",
    "var_ecartees.append((\"secu3\", \"Dichotomisation\"))\n",
    "#df = df.drop([\"secu1\", \"secu2\", \"secu3\"], axis = 1)\n",
    "log_action(f\"Dichotomisation des champs secu1, secu2 et secu3\")\n",
    "\n",
    "##############################################################################\n",
    "# Dichotomisation de l'âge\n",
    "# TODO : À affiner\n",
    "##############################################################################\n",
    "df[\"age_enfant\"]  = (df.age>=0) & (df.age<= 15)\n",
    "df[\"age_jeune\"]   = (df.age>15) & (df.age<= 25)\n",
    "df[\"age_adulte\"]  = (df.age>25) & (df.age<= 64)\n",
    "df[\"age_3age\"]    = (df.age>64)\n",
    "\n",
    "var_ecartees.append((\"age\", \"Dichotomisation\"))\n",
    "log_action(f\"Dichotomisation de l'âge\")\n",
    "\n",
    "##############################################################################\n",
    "# Dichotomisation de l'heure\n",
    "##############################################################################\n",
    "# TODO : faire un équilibrage\n",
    "df[\"hr_matin\"] = (df.hrmn>=\"0600\") & (df.hrmn<\"1200\") \n",
    "df[\"hr_midi\"]  = (df.hrmn>=\"1200\") & (df.hrmn<\"1400\") \n",
    "df[\"hr_am\"]    = (df.hrmn>=\"1400\") & (df.hrmn<\"1800\") \n",
    "df[\"hr_soir\"]  = (df.hrmn>=\"1800\") & (df.hrmn<\"2100\") \n",
    "df[\"hr_nuit\"]  = (df.hrmn>=\"2100\") | (df.hrmn<\"0600\") \n",
    "\n",
    "var_ecartees.append((\"hrmn\", \"Dichotomisation\"))\n",
    "log_action(f\"Dichotomisation de l'heure\")\n",
    "\n",
    "##############################################################################\n",
    "# Dichotomisation du sexe\n",
    "##############################################################################\n",
    "df[\"sexe_m\"] = df.sexe == '1'\n",
    "df[\"sexe_f\"] = df.sexe == '2'\n",
    "\n",
    "var_ecartees.append((\"sexe\", \"Dichotomisation\"))\n",
    "log_action(f\"Dichotomisation du sexe\")\n",
    "\n",
    "##############################################################################\n",
    "# Dichotomisation de la gravité\n",
    "##############################################################################\n",
    "# Les noms de variables seront plus faciles à retenir que les valeurs 1 à 4\n",
    "# N.B.: les observations dont la gravité est inconnue (codée -1) seront écartées\n",
    "#df[\"grav_tue\"]         = df.grav == '2'\n",
    "#df[\"grav_blessehosp\"]  = df.grav == '3'\n",
    "#df[\"grav_blesseleger\"] = df.grav == '4'\n",
    "#df[\"grav_indemne\"]     = df.grav == '1'\n",
    "df[\"grav_grave\"]       = df.grav.isin([\"2\", \"3\"])\n",
    "\n",
    "var_ecartees.append((\"grav\", \"Dichotomisation\"))\n",
    "log_action(f\"Dichotomisation de la gravité\")\n",
    "\n",
    "##############################################################################\n",
    "# Dichotomisation du nombre de voies de circulation avec regroupement\n",
    "##############################################################################\n",
    "df[\"nbv_1\"]    = df.nbv == '1'\n",
    "df[\"nbv_2\"]    = df.nbv == '2'\n",
    "df[\"nbv_3\"]    = df.nbv == '3'\n",
    "df[\"nbv_4\"]    = df.nbv == '4'\n",
    "df[\"nbv_plus\"] = df.nbv.isin(['5', '6', '7', '8', '9', '10','11', '12'])\n",
    "\n",
    "var_ecartees.append((\"nbv\", \"Dichotomisation\"))\n",
    "log_action(f\"Dichotomisation du nombre de voies avec regroupement 1 à 4 puis 5 et plus\")\n",
    "\n",
    "##############################################################################\n",
    "# Dichotomisation de l'état de la surface\n",
    "##############################################################################\n",
    "#\n",
    "df[\"surf_norm\"]  = df.surf == '1'\n",
    "df[\"surf_mouil\"] = df.surf == '2'\n",
    "df[\"surf_gliss\"] = df.surf.isin(['3', '4', '5', '6', '7', '8', '9'])\n",
    "df[\"surf_autre\"] = df.surf == '9'\n",
    "\n",
    "var_ecartees.append((\"surf\", \"Dichotomisation\"))\n",
    "log_action(f\"Dichotomisation du l'état de la surface : sèche, mouillée, glissante (3 à 9)\")\n",
    "\n",
    "##############################################################################\n",
    "# Dichotomisation de la vitesse maximale autorisée\n",
    "##############################################################################\n",
    "# la vma (vitesse maximale autorisée) est codée par un flottant\n",
    "# Il y a des valeurs abberrantes et codées avec des points décimaux\n",
    "# Nous les convertissons en entiers\n",
    "vma_int = df.vma.astype(int)\n",
    "df[\"vma_30m\"] = vma_int.isin([10, 20, 30])\n",
    "df[\"vma_40\"]  = vma_int == 40\n",
    "df[\"vma_50\"]  = vma_int == 50\n",
    "df[\"vma_60\"]  = vma_int == 60\n",
    "df[\"vma_70\"]  = vma_int == 70\n",
    "df[\"vma_80\"]  = vma_int == 80\n",
    "df[\"vma_90\"]  = vma_int == 90\n",
    "df[\"vma_110\"] = vma_int == 110\n",
    "df[\"vma_130\"] = vma_int == 130\n",
    "\n",
    "var_ecartees.append((\"vma\", \"Dichotomisation\"))\n",
    "log_action(f\"Dichotomisation de la vitesse maximale autorisée avec regroupement\")\n",
    "\n",
    "##############################################################################\n",
    "# agg : En ou hors agglomération\n",
    "##############################################################################\n",
    "# modalités 1 et 2, sans valueurs nulles (-1 ou na)\n",
    "df.agg_agg = df.agg == '1'\n",
    "var_ecartees.append((\"agg\", \"Dichotomisation\"))\n",
    "log_action(\"Dichotomisation en ou hors agglomération (agg), 1 agglomération, 0 hors agglomoration\")\n",
    "\n",
    "##############################################################################\n",
    "# Dichotomisations plus simples\n",
    "##############################################################################\n",
    "\n",
    "# actp : action du piéton\n",
    "dummies = ['1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B']\n",
    "dichotomisation(df, \"actp\", var_ecartees, desc_vars, dummies = dummies)\n",
    "log_action(\"Dichotomisation de l'action du piéton (actp), modalité -1 0 et B exclues\")\n",
    "\n",
    "# atm : Conditions atmosphériques\n",
    "dummies = ['1', '2', '3', '4', '5', '6', '7', '8']\n",
    "dichotomisation(df, \"atm\", var_ecartees, desc_vars, dummies = dummies)\n",
    "log_action(\"Dichotomisation des cond. atmosphériques (atm), modalité -1 et 9 exclues\")\n",
    "\n",
    "# catr : Catégorie de route\n",
    "dummies = ['1', '2', '3', '4', '5', '6', '7']\n",
    "dichotomisation(df, \"catr\", var_ecartees, desc_vars, dummies = dummies)\n",
    "log_action(\"Dichotomisation de la catégorie de route (catr)), modalité -1 et 9 exclues\")\n",
    "\n",
    "# catu : Catégorie d'usager\n",
    "dummies = ['1', '2', '3']\n",
    "dichotomisation(df, \"catu\", var_ecartees, desc_vars, dummies = dummies)\n",
    "log_action(\"Dichotomisation de la catégorie d'usager (catu), modalité -1 exclue\")\n",
    "\n",
    "# catv : Catégorie de véhicule\n",
    "dichotomisation(df, \"catv\", var_ecartees, desc_vars, dummies = None, mod_ecartees=[0, -1])\n",
    "log_action(\"Dichotomisation de la catégorie de véhicule (catv), modalité -1 et 0 exclues\")\n",
    "\n",
    "# choc : Point de choc initial\n",
    "dichotomisation(df, \"choc\", var_ecartees, desc_vars, dummies = None, mod_ecartees=['0', '-1'])\n",
    "log_action(\"Dichotomisation du point de choc initial (choc), modalité -1 et 0 exclues\")\n",
    "\n",
    "# circ : Circulation\n",
    "dichotomisation(df, \"circ\", var_ecartees, desc_vars, dummies = None, mod_ecartees=['-1'])\n",
    "log_action(\"Dichotomisation du régime de circulation (circ), modalité -1 exclue\")\n",
    "\n",
    "# col : Type de collision\n",
    "dichotomisation(df, \"col\", var_ecartees, desc_vars, dummies = None, mod_ecartees=['-1'])\n",
    "log_action(\"Dichotomisation du type de collision (col), modalité -1 exclue\")\n",
    "\n",
    "# etatp: Piéton seul\n",
    "dichotomisation(df, \"etatp\", var_ecartees, desc_vars, dummies = ['1', '2', '3'])\n",
    "log_action(\"Dichotomisation de (etatp), modalité -1 exclue\")\n",
    "\n",
    "# infra : Aménagement - infrastructure\n",
    "dichotomisation(df, \"infra\", var_ecartees, desc_vars, dummies = None, mod_ecartees=['-1', '0'])\n",
    "log_action(\"Dichotomisation de Aménagement - infrastructure (infra), modalités -1 et 0 exclues\")\n",
    "\n",
    "# int : type d'intersection\n",
    "dichotomisation(df, \"int\", var_ecartees, desc_vars, dummies = None, mod_ecartees=['-1'])\n",
    "log_action(\"Dichotomisation du type d'intersection (int), modalité -1  exclues\")\n",
    "\n",
    "# jsem : Jour de la semaine\n",
    "dichotomisation(df, \"jsem\", var_ecartees, desc_vars, dummies = None, mod_ecartees=None)\n",
    "log_action(\"Dichotomisation du jour de la semaine (jsem), toutes modalité \")\n",
    "\n",
    "# locp : Localisation du piéton\n",
    "dichotomisation(df, \"locp\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1', '0'])\n",
    "log_action(\"Dichotomisation de la localisation du piéton (locp), modalités -1, 0(non renseigné) exclues\")\n",
    "\n",
    "# lum : Lumière modalité\n",
    "dichotomisation(df, \"lum\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1'])\n",
    "log_action(\"Dichotomisation des conditions lumineuses (lum), modalité -1 exclue\")\n",
    "\n",
    "# manv : Manœuvre\n",
    "dichotomisation(df, \"manv\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1', '0'])\n",
    "log_action(\"Dichotomisation de la manœuvre (manv), modalité -1 et 0 exclues\")\n",
    "\n",
    "# mois : Mois\n",
    "dichotomisation(df, \"mois\", var_ecartees, desc_vars, dummies = None, mod_ecartees = None)\n",
    "log_action(\"Dichotomisation du mois (mois), toutes modalités\")\n",
    "\n",
    "# motor : Motorisation\n",
    "dichotomisation(df, \"motor\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1', '0'])\n",
    "log_action(\"Dichotomisation de la motorisation (motor), modalité -1 et 0 exclues\")\n",
    "\n",
    "# obs : Obstacle fixe heurté\n",
    "dichotomisation(df, \"obs\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1', '0'])\n",
    "log_action(\"Dichotomisation de l'obstacle fixe heurté (obs), modalité -1 et 0 exclues\")\n",
    "\n",
    "# obsm : Obstacle mobile heurté\n",
    "dichotomisation(df, \"obsm\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1', '0'])\n",
    "log_action(\"Dichotomisation de l'obstacle mobile heurté (obsm), modalité -1 et 0 exclues\")\n",
    "\n",
    "# place : Place de l'usager dans le véhicule\n",
    "dichotomisation(df, \"place\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1'])\n",
    "log_action(\"Dichotomisation de la place dans le véhicule (place), modalité -1 exclue\")\n",
    "\n",
    "# plan : Tracé en plan\n",
    "dichotomisation(df, \"plan\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1'])\n",
    "log_action(\"Dichotomisation du tracé en plan (plan), modalité -1 exclue\")\n",
    "\n",
    "# prof : Déclivité\n",
    "dichotomisation(df, \"prof\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1'])\n",
    "log_action(\"Dichotomisation de la déclivité (prof), modalité -1 exclue\")\n",
    "\n",
    "# senc : sens de circulation\n",
    "dichotomisation(df, \"senc\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1'])\n",
    "log_action(\"Dichotomisation du sens de circulation (senc), modalité -1, 0 et 3 exclues\")\n",
    "\n",
    "# situ : Situation de l'accident\n",
    "dichotomisation(df, \"situ\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1'])\n",
    "log_action(\"Dichotomisation de la situation de l'accident (situ), modalité -1 exclue\")\n",
    "\n",
    "# trajet : Motif du trajet\n",
    "dichotomisation(df, \"trajet\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1'])\n",
    "log_action(\"Dichotomisation du motif du trajet (trajet), modalité -1 exclue\")\n",
    "\n",
    "# vosp : Présence d'une voie réservée\n",
    "dichotomisation(df, \"vosp\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1'])\n",
    "log_action(\"Dichotomisation de la présence d'une voie réservée (vosp), modalités -1 exclue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "408ed721e63149409d0229ebcce8959e",
    "deepnote_cell_type": "code",
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 1,
    "execution_start": 1725370987342,
    "source_hash": "72854dcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matin      :  128204\n",
      "Midi       :  51051\n",
      "après-midi :  141102\n",
      "soir       :  95798\n",
      "Nuit       :  78027\n"
     ]
    }
   ],
   "source": [
    "print (\"Matin      : \", df.hr_matin.sum())\n",
    "print (\"Midi       : \", df.hr_midi.sum())\n",
    "print (\"après-midi : \", df.hr_am.sum())\n",
    "print (\"soir       : \", df.hr_soir.sum())\n",
    "print (\"Nuit       : \", df.hr_nuit.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "2a10f430b1ba45b7862594bd5413b128",
    "deepnote_cell_type": "code",
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 1,
    "execution_start": 1725370987398,
    "source_hash": "6e716eec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enfants  :  30341\n",
      "jeunes   :  118147\n",
      "adultes  :  287571\n",
      "3ème âge :  52182\n"
     ]
    }
   ],
   "source": [
    "print (\"Enfants  : \", df.age_enfant.sum())\n",
    "print (\"jeunes   : \", df.age_jeune.sum())\n",
    "print (\"adultes  : \", df.age_adulte.sum())\n",
    "print (\"3ème âge : \", df.age_3age.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "a4b4a3dba85b4ee2b1acd09b2fb146bd",
    "deepnote_cell_type": "code",
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 0,
    "execution_start": 1725370987451,
    "source_hash": "3d86bae4"
   },
   "outputs": [],
   "source": [
    "# Pour mise au point, cellule à supprimer ultérieurement\n",
    "\n",
    "#df.loc[df.secu1 == 1, \"secu_ceinture\"].value_counts()\n",
    "#df[df.secu1 == '2'].shape\n",
    "#df.secu1.value_counts()\n",
    "#df.info()\n",
    "#print (df.vma.value_counts())\n",
    "#vvv = df.vma.astype(int)\n",
    "#print (vvv.value_counts())\n",
    "\n",
    "#print(df[\"agg\"].value_counts())\n",
    "#print(df[\"agg\"].isnull().sum())\n",
    "\n",
    "# @"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "42a8af6530aa496a93b3b2c98855b16d",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Suppression de variables\n",
    "Nous supprimons des variables pour les raisons suivantes :\n",
    "  - Codage douteux, valeurs trop dispersées ;\n",
    "  - Remplacées par d'autres variables (calculées) ;\n",
    "  - variables dichotomisées ;\n",
    "  - Index servant aux jointures et n'expliquant rien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "372e4167def44f8ca87e45c81b98632c",
    "deepnote_cell_type": "code",
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 437,
    "execution_start": 1725370987507,
    "source_hash": "c1a4017"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables à supprimer :  ['infra', 'vosp', 'nbv', 'pr', 'v2', 'catv', 'num_veh', 'choc', 'etatp', 'id_vehicule', 'Num_Acc', 'id_usager', 'larrout', 'occutc', 'motor', 'mois', 'manv', 'sexe', 'col', 'jsem', 'jour', 'lartpc', 'atm', 'an_nais', 'an', 'agg', 'secu3', 'prof', 'plan', 'catu', 'actp', 'obsm', 'grav', 'vma', 'dep', 'obs', 'long', 'circ', 'lat', 'v1', 'lum', 'adr', 'pr1', 'age', 'int', 'locp', 'situ', 'place', 'senc', 'trajet', 'catr', 'voie', 'secu1', 'com', 'secu2', 'hrmn', 'surf']\n",
      "Il reste les 265 colonnes suivantes : ['ferie', 'secu_ceinture', 'secu_casque', 'secu_dispenfant', 'secu_gilet', 'secu_airbag23RM', 'secu_gants', 'age_enfant', 'age_jeune', 'age_adulte', 'age_3age', 'hr_matin', 'hr_midi', 'hr_am', 'hr_soir', 'hr_nuit', 'sexe_m', 'sexe_f', 'grav_grave', 'nbv_1', 'nbv_2', 'nbv_3', 'nbv_4', 'nbv_plus', 'surf_norm', 'surf_mouil', 'surf_gliss', 'surf_autre', 'vma_30m', 'vma_40', 'vma_50', 'vma_60', 'vma_70', 'vma_80', 'vma_90', 'vma_110', 'vma_130', 'actp_1', 'actp_2', 'actp_3', 'actp_4', 'actp_5', 'actp_6', 'actp_7', 'actp_8', 'actp_9', 'actp_A', 'actp_B', 'atm_1', 'atm_2', 'atm_3', 'atm_4', 'atm_5', 'atm_6', 'atm_7', 'atm_8', 'catr_1', 'catr_2', 'catr_3', 'catr_4', 'catr_5', 'catr_6', 'catr_7', 'catu_1', 'catu_2', 'catu_3', 'catv_7', 'catv_17', 'catv_33', 'catv_42', 'catv_30', 'catv_37', 'catv_32', 'catv_50', 'catv_38', 'catv_10', 'catv_1', 'catv_40', 'catv_15', 'catv_14', 'catv_99', 'catv_2', 'catv_80', 'catv_34', 'catv_60', 'catv_31', 'catv_21', 'catv_3', 'catv_13', 'catv_20', 'catv_43', 'catv_36', 'catv_39', 'catv_16', 'catv_35', 'catv_41', 'choc_5', 'choc_3', 'choc_1', 'choc_4', 'choc_2', 'choc_8', 'choc_6', 'choc_7', 'choc_9', 'circ_3', 'circ_1', 'circ_2', 'circ_4', 'col_2', 'col_6', 'col_4', 'col_3', 'col_5', 'col_7', 'col_1', 'etatp_1', 'etatp_2', 'etatp_3', 'infra_2', 'infra_9', 'infra_1', 'infra_5', 'infra_4', 'infra_6', 'infra_3', 'infra_8', 'infra_7', 'int_1', 'int_3', 'int_9', 'int_4', 'int_2', 'int_6', 'int_5', 'int_7', 'int_8', 'jsem_6', 'jsem_4', 'jsem_5', 'jsem_3', 'jsem_1', 'jsem_2', 'jsem_7', 'locp_2', 'locp_3', 'locp_1', 'locp_5', 'locp_4', 'locp_8', 'locp_9', 'locp_6', 'locp_7', 'lum_4', 'lum_3', 'lum_1', 'lum_5', 'lum_2', 'manv_23', 'manv_11', 'manv_2', 'manv_21', 'manv_1', 'manv_9', 'manv_26', 'manv_15', 'manv_17', 'manv_4', 'manv_12', 'manv_16', 'manv_19', 'manv_13', 'manv_14', 'manv_3', 'manv_10', 'manv_5', 'manv_24', 'manv_18', 'manv_20', 'manv_7', 'manv_22', 'manv_25', 'manv_6', 'manv_8', 'mois_11', 'mois_9', 'mois_7', 'mois_2', 'mois_1', 'mois_5', 'mois_4', 'mois_8', 'mois_6', 'mois_10', 'mois_3', 'mois_12', 'motor_1', 'motor_6', 'motor_3', 'motor_5', 'motor_2', 'motor_4', 'obs_1', 'obs_4', 'obs_14', 'obs_9', 'obs_6', 'obs_15', 'obs_13', 'obs_8', 'obs_2', 'obs_16', 'obs_12', 'obs_3', 'obs_7', 'obs_17', 'obs_11', 'obs_5', 'obs_10', 'obsm_2', 'obsm_1', 'obsm_9', 'obsm_6', 'obsm_4', 'obsm_5', 'place_2', 'place_1', 'place_10', 'place_3', 'place_4', 'place_7', 'place_9', 'place_6', 'place_8', 'place_5', 'plan_2', 'plan_3', 'plan_1', 'plan_4', 'prof_1', 'prof_4', 'prof_2', 'prof_3', 'senc_2', 'senc_1', 'senc_3', 'senc_0', 'situ_1', 'situ_2', 'situ_4', 'situ_6', 'situ_8', 'situ_3', 'situ_5', 'trajet_0', 'trajet_5', 'trajet_9', 'trajet_1', 'trajet_4', 'trajet_2', 'trajet_3', 'vosp_0', 'vosp_1', 'vosp_3', 'vosp_2']\n",
      "Valeurs nulles :\n",
      " ferie              0\n",
      "secu_ceinture      0\n",
      "secu_casque        0\n",
      "secu_dispenfant    0\n",
      "secu_gilet         0\n",
      "                  ..\n",
      "trajet_3           0\n",
      "vosp_0             0\n",
      "vosp_1             0\n",
      "vosp_3             0\n",
      "vosp_2             0\n",
      "Length: 265, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Ajout à la liste des variables trop dispersées ou douteuses pour suppression\n",
    "##############################################################################\n",
    "var_ecartees.append((\"adr\",     \"Dispersion trop importante\"))\n",
    "var_ecartees.append((\"com\",     \"Dispersion trop importante\"))\n",
    "var_ecartees.append((\"dep\",     \"Dispersion trop importante\"))\n",
    "var_ecartees.append((\"larrout\", \"Valeurs douteuses\"))\n",
    "var_ecartees.append((\"lartpc\",  \"Valeurs douteuses\"))\n",
    "var_ecartees.append((\"lat\",     \"Valeurs douteuses\"))\n",
    "var_ecartees.append((\"long\",    \"Valeurs douteuses\"))\n",
    "var_ecartees.append((\"occutc\",  \"trop de nuls\"))\n",
    "var_ecartees.append((\"pr\",      \"Dispersion\"))\n",
    "var_ecartees.append((\"pr1\",     \"Dispersion\"))\n",
    "var_ecartees.append((\"v1\",      \"Dispersion\"))\n",
    "var_ecartees.append((\"v2\",      \"Dispersion\"))\n",
    "var_ecartees.append((\"voie\",    \"Dispersion\"))\n",
    "\n",
    "##############################################################################\n",
    "# Ajout à la liste des variables remplacées (calculées) pour suppression\n",
    "##############################################################################\n",
    "var_ecartees.append((\"an\",      \"Utilisée pour déterminer les jours fériés et l'âge puis supprimée\"))\n",
    "var_ecartees.append((\"an_nais\", \"Utilisée avec 'an' pour calculer l'âge puis supprimée\"))\n",
    "var_ecartees.append((\"jour\",    \"Utilisée pour déterminer si le jour est férié puis suppimée\"))\n",
    "\n",
    "##############################################################################\n",
    "# Ajout à la liste des variables dichotomisées pour suppression\n",
    "##############################################################################\n",
    "# Les noms des variables ont déjà été ajoutées à var_ecartees\n",
    "# par la fonction dichotomisation.\n",
    "\n",
    "##############################################################################\n",
    "# Ajout à la liste des variables d'index pour suppression\n",
    "##############################################################################\n",
    "\n",
    "var_ecartees.append((\"Num_Acc\",      \"Variable d'index\"))\n",
    "var_ecartees.append((\"id_usager\",    \"Variable d'index\"))\n",
    "var_ecartees.append((\"id_vehicule\",  \"Variable d'index\"))\n",
    "var_ecartees.append((\"num_veh\",      \"Variable d'index\"))\n",
    "\n",
    "variables_a_supprimer = [ve[0] for ve in var_ecartees]\n",
    "\n",
    "# Lors de la mise au point de ce notebook la liste des variables à écarter\n",
    "# est complétée avec des valeurs déjà présentes, drop est alors perturbée\n",
    "# et ne supprime pas les variables. Il faut supprimer les doublons.\n",
    "# C'est fait en convertissant la liste en ensmblme (set)\n",
    "# puis en la recovertissant en liste.\n",
    "variables_a_supprimer = set(variables_a_supprimer)\n",
    "variables_a_supprimer = list(variables_a_supprimer)\n",
    "\n",
    "print (\"Variables à supprimer : \", variables_a_supprimer)\n",
    "df = df.drop (columns = variables_a_supprimer, axis = 1)\n",
    "\n",
    "#print (f\"Il reste les {df.shape[1]} colonnes suivantes :\\n\", df.columns)\n",
    "print(f\"Il reste les {df.shape[1]} colonnes suivantes :\", end=\" \")\n",
    "print(\"[\" + \", \".join(f\"'{col}'\" for col in df.columns) + \"]\")\n",
    "\n",
    "print (\"Valeurs nulles :\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "aa24ebe18f804297aa8132a5aed1559b",
    "deepnote_cell_type": "code",
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 1,
    "execution_start": 1725370987990,
    "source_hash": "fe094c23"
   },
   "outputs": [],
   "source": [
    "# Suppression de doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "87c6fa35a07f4d8ba0e09082454bba1a",
    "deepnote_cell_type": "code",
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 1734,
    "execution_start": 1725370988042,
    "source_hash": "9f654320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suppression d'observations :\n",
      "  avant suppression  494182\n",
      "  nous supprimons      3534\n",
      "  après suppression  490648\n"
     ]
    }
   ],
   "source": [
    "avant_supp = df.shape[0]\n",
    "df = df.drop_duplicates()\n",
    "apres_supp = df.shape[0]\n",
    "print (\"Suppression d'observations :\")\n",
    "print (f\"  avant suppression {avant_supp:7d}\")\n",
    "print (f\"  nous supprimons   {avant_supp - apres_supp:7d}\")\n",
    "print (f\"  après suppression {apres_supp:7d}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "228086f1109a4484acb85d97cf9c55af",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Équilibrage ou réduction de dimension\n",
    "La répartition des modalités de la variable cible est très déséquilibrée\n",
    "Notre objectif est de prédire les conditions des accidents ayant ayant entraîné une hospitalisation de plus de 24h ou le décès.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": "e9d6b5973a424e4898b2ee3d98086392",
    "deepnote_cell_type": "code",
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 797,
    "execution_start": 1725371604482,
    "scrolled": true,
    "source_hash": "54a7618c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition avant réduction :\n",
      "grav_grave\n",
      "False    401827\n",
      "True      88821\n",
      "Name: count, dtype: int64\n",
      "total : 490648\n",
      "Répartition après réduction :\n",
      "grav_grave\n",
      "False    88821\n",
      "True     88821\n",
      "Name: count, dtype: int64\n",
      "total :177642\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Équilibrage des modalités de la variable cible\n",
    "##############################################################################\n",
    "\n",
    "df2 = df # Copie pour mise au point et reprise rapide possible du jeu de données\n",
    "print (\"Répartition avant réduction :\")\n",
    "print (df2.value_counts(\"grav_grave\"))\n",
    "print (f\"total : {df2.shape[0]:6d}\")\n",
    "X = df2.drop(\"grav_grave\", axis = 1)\n",
    "y = df2.grav_grave\n",
    "rus = RandomUnderSampler(random_state = 8421)\n",
    "X, y = rus.fit_resample(X, y)\n",
    "df2 = pd.concat([X, y], axis = 1)\n",
    "print (\"Répartition après réduction :\")\n",
    "print(df2.value_counts(\"grav_grave\"))\n",
    "print (f\"total :{df2.shape[0]:6d}\")\n",
    "df = df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "98250a0a04df490fa9dad6cdc3528a44",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 0,
    "execution_start": 1724485927891,
    "scrolled": true,
    "source_hash": "e81f2b30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grav_grave\n",
       "False    401827\n",
       "True      88821\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.grav_grave.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "d1cc6f6213ea413c9c6029fce93469ea",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 0,
    "execution_start": 1724485927939,
    "source_hash": "b623e53d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": "6257836513f6437eb5e9ccd3729b2e1f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 38,
    "execution_start": 1724485927991,
    "source_hash": "42b943ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ferie              26823  15.0994697%\n",
      "secu_ceinture      87675  49.3548823%\n",
      "secu_casque        44043  24.7931232%\n",
      "secu_dispenfant     1134   0.6383625%\n",
      "secu_gilet          1544   0.8691638%\n",
      "secu_airbag23RM     2544   1.4320938%\n",
      "secu_gants         22555  12.6968847%\n",
      "age_enfant         10647   5.9935150%\n",
      "age_jeune          43476  24.4739420%\n",
      "age_adulte         98843  55.6416838%\n",
      "age_3age           23322  13.1286520%\n",
      "hr_matin           44999  25.3312843%\n",
      "hr_midi            17455   9.8259421%\n",
      "hr_am              50438  28.3930602%\n",
      "hr_soir            33917  19.0928947%\n",
      "hr_nuit            30833  17.3568188%\n",
      "sexe_m            123056  69.2719064%\n",
      "sexe_f             53266  29.9850261%\n",
      "nbv_1              15243   8.5807410%\n",
      "nbv_2             116207  65.4163993%\n",
      "nbv_3              12510   7.0422535%\n",
      "nbv_4              19456  10.9523649%\n",
      "nbv_plus            9051   5.0950789%\n",
      "surf_norm         144071  81.1018791%\n",
      "surf_mouil         30492  17.1648597%\n",
      "surf_gliss          3033   1.7073665%\n",
      "surf_autre          1103   0.6209117%\n",
      "vma_30m            15286   8.6049470%\n",
      "vma_40               188   0.1058308%\n",
      "vma_50             83140  46.8019950%\n",
      "vma_60               558   0.3141149%\n",
      "vma_70             13929   7.8410511%\n",
      "vma_80             36575  20.5891625%\n",
      "vma_90             12587   7.0855991%\n",
      "vma_110             6583   3.7057678%\n",
      "vma_130             4926   2.7729929%\n",
      "actp_1              1296   0.7295572%\n",
      "actp_2               622   0.3501424%\n",
      "actp_3             12867   7.2432195%\n",
      "actp_4               249   0.1401696%\n",
      "actp_5               643   0.3619639%\n",
      "actp_6                73   0.0410939%\n",
      "actp_7                26   0.0146362%\n",
      "actp_8                32   0.0180138%\n",
      "actp_9              1272   0.7160469%\n",
      "actp_A               214   0.1204670%\n",
      "actp_B               648   0.3647786%\n",
      "atm_1             142078  79.9799597%\n",
      "atm_2              17554   9.8816721%\n",
      "atm_3               3882   2.1852940%\n",
      "atm_4                702   0.3951768%\n",
      "atm_5               1506   0.8477725%\n",
      "atm_6                588   0.3310028%\n",
      "atm_7               3847   2.1655915%\n",
      "atm_8               6534   3.6781842%\n",
      "catr_1             16839   9.4791772%\n",
      "catr_2             13273   7.4717691%\n",
      "catr_3             77225  43.4722644%\n",
      "catr_4             61961  34.8797019%\n",
      "catr_5               218   0.1227187%\n",
      "catr_6              1212   0.6822711%\n",
      "catr_7              5640   3.1749248%\n",
      "catu_1            128803  72.5070648%\n",
      "catu_2             30631  17.2431069%\n",
      "catu_3             18208  10.2498283%\n",
      "catv_7            103569  58.3020907%\n",
      "catv_17              875   0.4925637%\n",
      "catv_33            18476  10.4006935%\n",
      "catv_42               35   0.0197025%\n",
      "catv_30             4961   2.7926954%\n",
      "catv_37             1160   0.6529987%\n",
      "catv_32             3946   2.2213215%\n",
      "catv_50             1921   1.0813884%\n",
      "catv_38              361   0.2032177%\n",
      "catv_10             9974   5.6146632%\n",
      "catv_1              9545   5.3731663%\n",
      "catv_40              227   0.1277851%\n",
      "catv_15             1171   0.6591910%\n",
      "catv_14             1031   0.5803808%\n",
      "catv_99              735   0.4137535%\n",
      "catv_2              8391   4.7235451%\n",
      "catv_80              853   0.4801792%\n",
      "catv_34             2129   1.1984778%\n",
      "catv_60              270   0.1519911%\n",
      "catv_31             3732   2.1008545%\n",
      "catv_21              359   0.2020918%\n",
      "catv_3              1115   0.6276669%\n",
      "catv_13              510   0.2870943%\n",
      "catv_20              196   0.1103343%\n",
      "catv_43              866   0.4874973%\n",
      "catv_36              603   0.3394468%\n",
      "catv_39               78   0.0439085%\n",
      "catv_16               42   0.0236431%\n",
      "catv_35               66   0.0371534%\n",
      "catv_41               29   0.0163250%\n",
      "choc_5              3806   2.1425113%\n",
      "choc_3             25343  14.2663334%\n",
      "choc_1             71107  40.0282591%\n",
      "choc_4             13443   7.5674672%\n",
      "choc_2             21599  12.1587237%\n",
      "choc_8             11503   6.4753831%\n",
      "choc_6              4713   2.6530888%\n",
      "choc_7             10284   5.7891715%\n",
      "choc_9              4060   2.2854955%\n",
      "circ_3             24629  13.8644014%\n",
      "circ_1             24928  14.0327175%\n",
      "circ_2            118295  66.5917970%\n",
      "circ_4              1064   0.5989575%\n",
      "col_2              20470  11.5231758%\n",
      "col_6              49799  28.0333480%\n",
      "col_4               8205   4.6188401%\n",
      "col_3              49656  27.9528490%\n",
      "col_5               8597   4.8395087%\n",
      "col_7              15880   8.9393274%\n",
      "col_1              23746  13.3673343%\n",
      "etatp_1            14206   7.9969827%\n",
      "etatp_2             3138   1.7664741%\n",
      "etatp_3              595   0.3349433%\n",
      "infra_2             3242   1.8250189%\n",
      "infra_9             6494   3.6556670%\n",
      "infra_1             1788   1.0065187%\n",
      "infra_5             9821   5.5285349%\n",
      "infra_4              557   0.3135520%\n",
      "infra_6             1349   0.7593925%\n",
      "infra_3             2232   1.2564596%\n",
      "infra_8             1279   0.7199874%\n",
      "infra_7              146   0.0821878%\n",
      "int_1             119088  67.0382004%\n",
      "int_3              17676   9.9503496%\n",
      "int_9               7522   4.2343590%\n",
      "int_4               3904   2.1976785%\n",
      "int_2              20358  11.4601277%\n",
      "int_6               6369   3.5853008%\n",
      "int_5                879   0.4948154%\n",
      "int_7               1484   0.8353880%\n",
      "int_8                353   0.1987143%\n",
      "jsem_6             27321  15.3798088%\n",
      "jsem_4             24761  13.9387082%\n",
      "jsem_5             29178  16.4251697%\n",
      "jsem_3             24653  13.8779118%\n",
      "jsem_1             23126  13.0183177%\n",
      "jsem_2             24420  13.7467491%\n",
      "jsem_7             24183  13.6133347%\n",
      "locp_2              3887   2.1881087%\n",
      "locp_3              5485   3.0876707%\n",
      "locp_1              3150   1.7732293%\n",
      "locp_5              1274   0.7171727%\n",
      "locp_4              2219   1.2491415%\n",
      "locp_8               255   0.1435471%\n",
      "locp_9               903   0.5083257%\n",
      "locp_6               693   0.3901104%\n",
      "locp_7                17   0.0095698%\n",
      "lum_4               1607   0.9046284%\n",
      "lum_3              21925  12.3422389%\n",
      "lum_1             117186  65.9675077%\n",
      "lum_5              24939  14.0389097%\n",
      "lum_2              11980   6.7439007%\n",
      "manv_23             3241   1.8244559%\n",
      "manv_11             1490   0.8387656%\n",
      "manv_2             16218   9.1295977%\n",
      "manv_21             2829   1.5925288%\n",
      "manv_1             79342  44.6639871%\n",
      "manv_9              4071   2.2916878%\n",
      "manv_26             6232   3.5081794%\n",
      "manv_15            11022   6.2046138%\n",
      "manv_17             6726   3.7862668%\n",
      "manv_4              1069   0.6017721%\n",
      "manv_12             1220   0.6867745%\n",
      "manv_16             4077   2.2950654%\n",
      "manv_19             4359   2.4538116%\n",
      "manv_13            10580   5.9557987%\n",
      "manv_14             4795   2.6992491%\n",
      "manv_3              1426   0.8027381%\n",
      "manv_10              875   0.4925637%\n",
      "manv_5              2342   1.3183819%\n",
      "manv_24              529   0.2977899%\n",
      "manv_18              868   0.4886232%\n",
      "manv_20              975   0.5488567%\n",
      "manv_7               372   0.2094099%\n",
      "manv_22              350   0.1970255%\n",
      "manv_25              479   0.2696434%\n",
      "manv_6               411   0.2313642%\n",
      "manv_8                78   0.0439085%\n",
      "mois_11            13538   7.6209455%\n",
      "mois_9             17206   9.6857725%\n",
      "mois_7             18292  10.2971144%\n",
      "mois_2             12857   7.2375902%\n",
      "mois_1             13095   7.3715675%\n",
      "mois_5             14885   8.3792121%\n",
      "mois_4             11175   6.2907421%\n",
      "mois_8             15828   8.9100551%\n",
      "mois_6             17205   9.6852096%\n",
      "mois_10            16650   9.3727835%\n",
      "mois_3             12520   7.0478828%\n",
      "mois_12            14391   8.1011247%\n",
      "motor_1           147932  83.2753515%\n",
      "motor_6             1656   0.9322120%\n",
      "motor_3             4450   2.5050382%\n",
      "motor_5             8923   5.0230238%\n",
      "motor_2             2223   1.2513933%\n",
      "motor_4               80   0.0450344%\n",
      "obs_1               4100   2.3080127%\n",
      "obs_4               2740   1.5424280%\n",
      "obs_14              1430   0.8049898%\n",
      "obs_9               1036   0.5831954%\n",
      "obs_6               3720   2.0940994%\n",
      "obs_15              1686   0.9490999%\n",
      "obs_13              6029   3.3939046%\n",
      "obs_8               3268   1.8396550%\n",
      "obs_2               5749   3.2362842%\n",
      "obs_16              1203   0.6772047%\n",
      "obs_12              1753   0.9868162%\n",
      "obs_3               3405   1.9167764%\n",
      "obs_7                857   0.4824310%\n",
      "obs_17               466   0.2623254%\n",
      "obs_11               433   0.2437487%\n",
      "obs_5                484   0.2724581%\n",
      "obs_10               344   0.1936479%\n",
      "obsm_2            103368  58.1889418%\n",
      "obsm_1             25704  14.4695511%\n",
      "obsm_9              1829   1.0295989%\n",
      "obsm_6               573   0.3225589%\n",
      "obsm_4               175   0.0985127%\n",
      "obsm_5               191   0.1075196%\n",
      "place_2            19799  11.1454498%\n",
      "place_1           128584  72.3837831%\n",
      "place_10           18208  10.2498283%\n",
      "place_3             2829   1.5925288%\n",
      "place_4             2594   1.4602403%\n",
      "place_7             1832   1.0312876%\n",
      "place_9             1955   1.1005280%\n",
      "place_6              208   0.1170894%\n",
      "place_8              782   0.4402112%\n",
      "place_5              845   0.4756758%\n",
      "plan_2             18402  10.3590367%\n",
      "plan_3             17742   9.9875030%\n",
      "plan_1            138553  77.9956317%\n",
      "plan_4              2916   1.6415037%\n",
      "prof_1            140236  78.9430427%\n",
      "prof_4              2884   1.6234899%\n",
      "prof_2             30968  17.4328143%\n",
      "prof_3              3520   1.9815134%\n",
      "senc_2             60934  34.3015728%\n",
      "senc_1             78928  44.4309341%\n",
      "senc_3             25654  14.4414046%\n",
      "senc_0             11613   6.5373054%\n",
      "situ_1            146293  82.3527094%\n",
      "situ_2              1658   0.9333378%\n",
      "situ_4              3302   1.8587947%\n",
      "situ_6              1771   0.9969489%\n",
      "situ_8              6045   3.4029115%\n",
      "situ_3             15898   8.9494602%\n",
      "situ_5              2583   1.4540480%\n",
      "trajet_0           42845  24.1187332%\n",
      "trajet_5           74379  41.8701658%\n",
      "trajet_9           13472   7.5837921%\n",
      "trajet_1           22603  12.7239054%\n",
      "trajet_4           12471   7.0202993%\n",
      "trajet_2            3552   1.9995271%\n",
      "trajet_3            6652   3.7446099%\n",
      "vosp_0            161126  90.7026491%\n",
      "vosp_1              6706   3.7750082%\n",
      "vosp_3              5335   3.0032312%\n",
      "vosp_2              3488   1.9634996%\n",
      "grav_grave         88821  50.0000000%\n"
     ]
    }
   ],
   "source": [
    "#df.info(max_cols=500)\n",
    "nb_obs = df.shape[0]\n",
    "for col in df.columns:\n",
    "    print(f\"{col:15s}   {df[col].sum():6d}  {100.*df[col].sum()/nb_obs:10.7f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": "c909a2d926154c3fa08f13298125c7e7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 0,
    "execution_start": 1724485928083,
    "source_hash": "2649655a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions réalisées :\n",
      "Jointure usagers  <---  caracteristiques\n",
      "Jointure (usagers et caracteristiques)  <---  lieux\n",
      "Jointure (usagers, caracteristiques et lieux)  <---  vehicules\n",
      "Suppression de 0 observations dont la gravité est inconnue (codée -1)\n",
      "Création de la variable jsem : jour de la semaine\n",
      "Création de la variable ferie : jour férié, dimanches et autres fêtes\n",
      "Création de la variable age : différence entre l'année de l'accident et l'année de naissance\n",
      "Dichotomisation des champs secu1, secu2 et secu3\n",
      "Dichotomisation de l'âge\n",
      "Dichotomisation de l'heure\n",
      "Dichotomisation du sexe\n",
      "Dichotomisation de la gravité\n",
      "Dichotomisation du nombre de voies avec regroupement 1 à 4 puis 5 et plus\n",
      "Dichotomisation du l'état de la surface : sèche, mouillée, glissante (3 à 9)\n",
      "Dichotomisation de la vitesse maximale autorisée avec regroupement\n",
      "Dichotomisation en ou hors agglomération (agg), 1 agglomération, 0 hors agglomoration\n",
      "Dichotomisation de l'action du piéton (actp), modalité -1 0 et B exclues\n",
      "Dichotomisation des cond. atmosphériques (atm), modalité -1 et 9 exclues\n",
      "Dichotomisation de la catégorie de route (catr)), modalité -1 et 9 exclues\n",
      "Dichotomisation de la catégorie d'usager (catu), modalité -1 exclue\n",
      "Dichotomisation de la catégorie de véhicule (catv), modalité -1 et 0 exclues\n",
      "Dichotomisation du point de choc initial (choc), modalité -1 et 0 exclues\n",
      "Dichotomisation du régime de circulation (circ), modalité -1 exclue\n",
      "Dichotomisation du type de collision (col), modalité -1 exclue\n",
      "Dichotomisation de (etatp), modalité -1 exclue\n",
      "Dichotomisation de Aménagement - infrastructure (infra), modalités -1 et 0 exclues\n",
      "Dichotomisation du type d'intersection (int), modalité -1  exclues\n",
      "Dichotomisation du jour de la semaine (jsem), toutes modalité \n",
      "Dichotomisation de la localisation du piéton (locp), modalités -1, 0(non renseigné) exclues\n",
      "Dichotomisation des conditions lumineuses (lum), modalité -1 exclue\n",
      "Dichotomisation de la manœuvre (manv), modalité -1 et 0 exclues\n",
      "Dichotomisation du mois (mois), toutes modalités\n",
      "Dichotomisation de la motorisation (motor), modalité -1 et 0 exclues\n",
      "Dichotomisation de l'obstacle fixe heurté (obs), modalité -1 et 0 exclues\n",
      "Dichotomisation de l'obstacle mobile heurté (obsm), modalité -1 et 0 exclues\n",
      "Dichotomisation de la place dans le véhicule (place), modalité -1 exclue\n",
      "Dichotomisation du tracé en plan (plan), modalité -1 exclue\n",
      "Dichotomisation de la déclivité (prof), modalité -1 exclue\n",
      "Dichotomisation du sens de circulation (senc), modalité -1, 0 et 3 exclues\n",
      "Dichotomisation de la situation de l'accident (situ), modalité -1 exclue\n",
      "Dichotomisation du motif du trajet (trajet), modalité -1 exclue\n",
      "Dichotomisation de la présence d'une voie réservée (vosp), modalités -1 exclue\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (\"Actions réalisées :\")\n",
    "for a in actions:\n",
    "    print (a)\n",
    "# print(\"Répartition des modalités de la cible :\")\n",
    "# print (df.grav.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8bbd79212dcb4752aeb44bf6626c0a01",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": []
   },
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": "91167aa8483b49539960c2b43f318c12",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "bfcb67da-9d80-4f22-851e-5ae1831000b6",
    "execution_millis": 19068,
    "execution_start": 1724485928139,
    "source_hash": "3b17b408"
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Enregistrements :\n",
    "#   - Le jeu de données préparé pour la modélisation ;\n",
    "#   - La description des variables mise à jour.\n",
    "##############################################################################\n",
    "\n",
    "df.to_csv(rep_dst + '/' + \"data.csv\", sep = '\\t', index=False, encoding='utf-8')\n",
    "\n",
    "#with open(\"./desc_vars.json\", 'w', encoding='utf-8') as fichier:\n",
    "#    json.dump(desc_vars, fichier, ensure_ascii=True, indent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=48c63c24-f1df-45c2-8e80-c8ef2e09cf67' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "2dec51ceb9bf4391b29e81337dba1028",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
